import asyncio
import json
import nltk
from app import AutoAgentSystem
from tools.sqlite_search import SQLiteSearch

nltk.download('punkt')

def split_claim_into_phrases(claim, max_phrases=5):
    from nltk.tokenize import sent_tokenize
    phrases = sent_tokenize(claim)
    return phrases[:max_phrases]

async def evaluate_dataset(dataset_path, num_examples=2):
    app = AutoAgentSystem(
        tool_configs={
            SQLiteSearch: {
                "always_include": True,
                "kwargs": {
                    "db_path": "C:/Users/USER/Downloads/Test_Agent/Test_5/Dataset/feverous_wikiv1.db"
                }
            }
        },
        root_has_tools=True
    )
    kani = await app.ensure_init()

    with open(dataset_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    lines = lines[:num_examples]

    results = []

    for line in lines:
        sample = json.loads(line)
        claim = sample["claim"]
        label = sample["label"]

        claim_phrases = split_claim_into_phrases(claim, max_phrases=5)

        print(f"\nğŸ§© Evaluating Claim ID {sample['id']}")
        print(f"Claim: {claim}")
        print(f"Ground Truth Label: {label}")

        instructions = []
        for phrase in claim_phrases:
            instructions.append(f"è«‹ä½¿ç”¨ search_by_text å·¥å…·ï¼Œæœå°‹èˆ‡ '{phrase}' ç›¸é—œçš„è³‡æ–™ï¼Œä¸¦ç¸½çµæ‰¾åˆ°çš„è­‰æ“šã€‚")

        # åªæœƒæ´¾ 5 å€‹ä»¥å…§ sub-agent
        for instr in instructions:
            await kani.delegator.delegate(instr)

        # ç­‰æ‰€æœ‰ sub agent å›ä¾†
        await kani.delegator.wait(until="all")

        # æ‰“å°æ‰€æœ‰ sub agent ä»»å‹™æƒ…æ³
        print("\n=== Sub-Agent ä»»å‹™åˆ—è¡¨ ===")
        for task in app.global_task_log:
            print(f"Agent {task['agent']} æŸ¥è©¢: {task['task']} â†’ ç‹€æ…‹: {task['status']}")

        print("=== å­ Agent å›å ±å®Œæˆ ===\n")

    await app.close()

if __name__ == "__main__":
    dataset_path = r"C:/Users/USER/Downloads/Test_Agent/Test_5/Dataset/feverous_dev_challenges.jsonl"
    asyncio.run(evaluate_dataset(dataset_path, num_examples=2))